# vLLM
> a fast and easy-to-use library for LLM inference and serving.

[doc](https://docs.vllm.ai/en/latest/)

# Limit
- Only for linux
  - `nvidia-cutlass-dsl` (v4.3.5) only has wheels for the following platforms: `manylinux_2_28_aarch64`, `manylinux_2_28_x86_64` 
